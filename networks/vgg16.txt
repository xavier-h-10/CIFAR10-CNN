ssh://root@hz-t3.matpool.com:29911/root/miniconda3/envs/myconda/bin/python -u /mnt/lee/cifar10_vgg16.py
2021-12-26 06:52:08.824255: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-12-26 06:52:14.038621: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-12-26 06:52:14.039993: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2021-12-26 06:52:14.116440: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:84:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2021-12-26 06:52:14.116499: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-12-26 06:52:14.119702: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-12-26 06:52:14.119765: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-12-26 06:52:14.121062: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-12-26 06:52:14.121733: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-12-26 06:52:14.125005: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-12-26 06:52:14.125707: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-12-26 06:52:14.125901: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-12-26 06:52:14.128899: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2021-12-26 06:52:14.129923: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-12-26 06:52:14.132451: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:84:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2021-12-26 06:52:14.132521: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-12-26 06:52:14.132596: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-12-26 06:52:14.132663: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-12-26 06:52:14.132730: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-12-26 06:52:14.132796: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-12-26 06:52:14.132877: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-12-26 06:52:14.132943: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-12-26 06:52:14.133005: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-12-26 06:52:14.137210: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2021-12-26 06:52:14.137297: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-12-26 06:52:14.853687: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-12-26 06:52:14.853740: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2021-12-26 06:52:14.853754: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2021-12-26 06:52:14.857959: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10073 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:84:00.0, compute capability: 7.5)
-------------load the model-----------------
2021-12-26 06:52:15.674375: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2021-12-26 06:52:15.697503: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2499990000 Hz
Epoch 1/100
2021-12-26 06:52:20.229689: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-12-26 06:52:20.783522: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-12-26 06:52:20.787671: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
1563/1563 [==============================] - 36s 18ms/step - loss: 1.7313 - sparse_categorical_accuracy: 0.3823 - val_loss: 1.4620 - val_sparse_categorical_accuracy: 0.4780
Epoch 2/100
1563/1563 [==============================] - 27s 17ms/step - loss: 1.3369 - sparse_categorical_accuracy: 0.5263 - val_loss: 1.3168 - val_sparse_categorical_accuracy: 0.5441
Epoch 3/100
1563/1563 [==============================] - 27s 17ms/step - loss: 1.1968 - sparse_categorical_accuracy: 0.5884 - val_loss: 1.1048 - val_sparse_categorical_accuracy: 0.6163
Epoch 4/100
1563/1563 [==============================] - 27s 17ms/step - loss: 1.0908 - sparse_categorical_accuracy: 0.6249 - val_loss: 1.1328 - val_sparse_categorical_accuracy: 0.6164
Epoch 5/100
1563/1563 [==============================] - 27s 17ms/step - loss: 1.0298 - sparse_categorical_accuracy: 0.6518 - val_loss: 1.0561 - val_sparse_categorical_accuracy: 0.6331
Epoch 6/100
1563/1563 [==============================] - 27s 17ms/step - loss: 0.9536 - sparse_categorical_accuracy: 0.6753 - val_loss: 0.9767 - val_sparse_categorical_accuracy: 0.6689
Epoch 7/100
1563/1563 [==============================] - 27s 17ms/step - loss: 0.8853 - sparse_categorical_accuracy: 0.6988 - val_loss: 1.0652 - val_sparse_categorical_accuracy: 0.6397
Epoch 8/100
1563/1563 [==============================] - 27s 17ms/step - loss: 0.8276 - sparse_categorical_accuracy: 0.7202 - val_loss: 1.0334 - val_sparse_categorical_accuracy: 0.6655
Epoch 9/100
1563/1563 [==============================] - 27s 17ms/step - loss: 0.7886 - sparse_categorical_accuracy: 0.7373 - val_loss: 0.9091 - val_sparse_categorical_accuracy: 0.6937
Epoch 10/100
1563/1563 [==============================] - 27s 17ms/step - loss: 0.7446 - sparse_categorical_accuracy: 0.7503 - val_loss: 0.9410 - val_sparse_categorical_accuracy: 0.6876
Epoch 11/100
1563/1563 [==============================] - 27s 17ms/step - loss: 0.6908 - sparse_categorical_accuracy: 0.7686 - val_loss: 0.9735 - val_sparse_categorical_accuracy: 0.6904
Epoch 12/100
1563/1563 [==============================] - 27s 17ms/step - loss: 0.6680 - sparse_categorical_accuracy: 0.7801 - val_loss: 0.9682 - val_sparse_categorical_accuracy: 0.6865
Epoch 13/100
1563/1563 [==============================] - 27s 17ms/step - loss: 0.6310 - sparse_categorical_accuracy: 0.7879 - val_loss: 0.8765 - val_sparse_categorical_accuracy: 0.7220
Epoch 14/100
1563/1563 [==============================] - 27s 17ms/step - loss: 0.5911 - sparse_categorical_accuracy: 0.8043 - val_loss: 0.9079 - val_sparse_categorical_accuracy: 0.7087
Epoch 15/100
1563/1563 [==============================] - 27s 17ms/step - loss: 0.5455 - sparse_categorical_accuracy: 0.8133 - val_loss: 0.9233 - val_sparse_categorical_accuracy: 0.7148
Epoch 16/100
1563/1563 [==============================] - 27s 17ms/step - loss: 0.5160 - sparse_categorical_accuracy: 0.8270 - val_loss: 0.8773 - val_sparse_categorical_accuracy: 0.7267
Epoch 17/100
1563/1563 [==============================] - 27s 17ms/step - loss: 0.5005 - sparse_categorical_accuracy: 0.8332 - val_loss: 0.8616 - val_sparse_categorical_accuracy: 0.7280
Epoch 18/100
1563/1563 [==============================] - 27s 17ms/step - loss: 0.4635 - sparse_categorical_accuracy: 0.8455 - val_loss: 0.8681 - val_sparse_categorical_accuracy: 0.7269
Epoch 19/100
1563/1563 [==============================] - 27s 17ms/step - loss: 0.4454 - sparse_categorical_accuracy: 0.8508 - val_loss: 0.9826 - val_sparse_categorical_accuracy: 0.7053
Epoch 20/100
1563/1563 [==============================] - 27s 17ms/step - loss: 0.4297 - sparse_categorical_accuracy: 0.8576 - val_loss: 0.9973 - val_sparse_categorical_accuracy: 0.7015
Epoch 21/100
1563/1563 [==============================] - 27s 17ms/step - loss: 0.3945 - sparse_categorical_accuracy: 0.8707 - val_loss: 0.8765 - val_sparse_categorical_accuracy: 0.7356
Epoch 22/100
1563/1563 [==============================] - 27s 17ms/step - loss: 0.3889 - sparse_categorical_accuracy: 0.8699 - val_loss: 0.9591 - val_sparse_categorical_accuracy: 0.7200
Epoch 23/100
1563/1563 [==============================] - 27s 17ms/step - loss: 0.3716 - sparse_categorical_accuracy: 0.8790 - val_loss: 0.9168 - val_sparse_categorical_accuracy: 0.7336
Epoch 24/100
1563/1563 [==============================] - 27s 17ms/step - loss: 0.3535 - sparse_categorical_accuracy: 0.8832 - val_loss: 0.9053 - val_sparse_categorical_accuracy: 0.7388
Epoch 25/100
1563/1563 [==============================] - 27s 17ms/step - loss: 0.3313 - sparse_categorical_accuracy: 0.8917 - val_loss: 0.9132 - val_sparse_categorical_accuracy: 0.7347
Epoch 26/100
1563/1563 [==============================] - 27s 17ms/step - loss: 0.3104 - sparse_categorical_accuracy: 0.8963 - val_loss: 1.0758 - val_sparse_categorical_accuracy: 0.7130
Epoch 27/100
1563/1563 [==============================] - 27s 17ms/step - loss: 0.3055 - sparse_categorical_accuracy: 0.8980 - val_loss: 0.9714 - val_sparse_categorical_accuracy: 0.7409
Epoch 28/100
1563/1563 [==============================] - 27s 17ms/step - loss: 0.2922 - sparse_categorical_accuracy: 0.9056 - val_loss: 0.9593 - val_sparse_categorical_accuracy: 0.7418
Epoch 29/100
1563/1563 [==============================] - 27s 17ms/step - loss: 0.2810 - sparse_categorical_accuracy: 0.9093 - val_loss: 1.0420 - val_sparse_categorical_accuracy: 0.7379
Epoch 30/100
1563/1563 [==============================] - 27s 17ms/step - loss: 0.2715 - sparse_categorical_accuracy: 0.9119 - val_loss: 1.3982 - val_sparse_categorical_accuracy: 0.6795
Epoch 31/100
1563/1563 [==============================] - 27s 17ms/step - loss: 0.2622 - sparse_categorical_accuracy: 0.9132 - val_loss: 1.0022 - val_sparse_categorical_accuracy: 0.7500
Epoch 32/100
1563/1563 [==============================] - 27s 17ms/step - loss: 0.2420 - sparse_categorical_accuracy: 0.9220 - val_loss: 0.9847 - val_sparse_categorical_accuracy: 0.7465
Epoch 33/100
1563/1563 [==============================] - 27s 17ms/step - loss: 0.2382 - sparse_categorical_accuracy: 0.9245 - val_loss: 1.0353 - val_sparse_categorical_accuracy: 0.7439
Epoch 34/100
1563/1563 [==============================] - 27s 17ms/step - loss: 0.2331 - sparse_categorical_accuracy: 0.9261 - val_loss: 1.0230 - val_sparse_categorical_accuracy: 0.7396
Epoch 35/100
1563/1563 [==============================] - 27s 17ms/step - loss: 0.2196 - sparse_categorical_accuracy: 0.9314 - val_loss: 1.0086 - val_sparse_categorical_accuracy: 0.7427
Epoch 36/100
1563/1563 [==============================] - 27s 17ms/step - loss: 0.2162 - sparse_categorical_accuracy: 0.9311 - val_loss: 1.0273 - val_sparse_categorical_accuracy: 0.7436
Epoch 37/100
1563/1563 [==============================] - 27s 17ms/step - loss: 0.1995 - sparse_categorical_accuracy: 0.9348 - val_loss: 1.0235 - val_sparse_categorical_accuracy: 0.7418
Epoch 38/100
1563/1563 [==============================] - 27s 17ms/step - loss: 0.1911 - sparse_categorical_accuracy: 0.9374 - val_loss: 1.1046 - val_sparse_categorical_accuracy: 0.7415
Epoch 39/100
1563/1563 [==============================] - 27s 17ms/step - loss: 0.1928 - sparse_categorical_accuracy: 0.9385 - val_loss: 1.1046 - val_sparse_categorical_accuracy: 0.7426
Epoch 40/100
1563/1563 [==============================] - 27s 17ms/step - loss: 0.1951 - sparse_categorical_accuracy: 0.9368 - val_loss: 1.1877 - val_sparse_categorical_accuracy: 0.7289
Epoch 41/100
1563/1563 [==============================] - 27s 17ms/step - loss: 0.1956 - sparse_categorical_accuracy: 0.9371 - val_loss: 1.1472 - val_sparse_categorical_accuracy: 0.7344
Epoch 42/100
1563/1563 [==============================] - 27s 17ms/step - loss: 0.1680 - sparse_categorical_accuracy: 0.9465 - val_loss: 1.0835 - val_sparse_categorical_accuracy: 0.7452
Epoch 43/100
1563/1563 [==============================] - 27s 17ms/step - loss: 0.1669 - sparse_categorical_accuracy: 0.9479 - val_loss: 1.1454 - val_sparse_categorical_accuracy: 0.7319
Epoch 44/100
1563/1563 [==============================] - 27s 17ms/step - loss: 0.1695 - sparse_categorical_accuracy: 0.9474 - val_loss: 1.2655 - val_sparse_categorical_accuracy: 0.7264
Epoch 45/100
1563/1563 [==============================] - 27s 17ms/step - loss: 0.1637 - sparse_categorical_accuracy: 0.9490 - val_loss: 1.0607 - val_sparse_categorical_accuracy: 0.7517
Epoch 46/100
1563/1563 [==============================] - 27s 17ms/step - loss: 0.1537 - sparse_categorical_accuracy: 0.9525 - val_loss: 1.1111 - val_sparse_categorical_accuracy: 0.7406
Epoch 47/100
1563/1563 [==============================] - 27s 17ms/step - loss: 0.1537 - sparse_categorical_accuracy: 0.9519 - val_loss: 1.1697 - val_sparse_categorical_accuracy: 0.7339
Epoch 48/100
1563/1563 [==============================] - 27s 17ms/step - loss: 0.1431 - sparse_categorical_accuracy: 0.9548 - val_loss: 1.0863 - val_sparse_categorical_accuracy: 0.7426
Epoch 49/100
1563/1563 [==============================] - 27s 17ms/step - loss: 0.1538 - sparse_categorical_accuracy: 0.9502 - val_loss: 1.0953 - val_sparse_categorical_accuracy: 0.7445
Epoch 50/100
1563/1563 [==============================] - 27s 17ms/step - loss: 0.1428 - sparse_categorical_accuracy: 0.9565 - val_loss: 1.1619 - val_sparse_categorical_accuracy: 0.7285
Epoch 51/100
1563/1563 [==============================] - 27s 17ms/step - loss: 0.1433 - sparse_categorical_accuracy: 0.9575 - val_loss: 1.1264 - val_sparse_categorical_accuracy: 0.7363
Epoch 52/100
1563/1563 [==============================] - 27s 17ms/step - loss: 0.1437 - sparse_categorical_accuracy: 0.9539 - val_loss: 1.0852 - val_sparse_categorical_accuracy: 0.7515
Epoch 53/100
1563/1563 [==============================] - 27s 17ms/step - loss: 0.1373 - sparse_categorical_accuracy: 0.9570 - val_loss: 1.5180 - val_sparse_categorical_accuracy: 0.6718
Epoch 54/100
1563/1563 [==============================] - 27s 17ms/step - loss: 0.1275 - sparse_categorical_accuracy: 0.9593 - val_loss: 1.2590 - val_sparse_categorical_accuracy: 0.7443
Epoch 55/100
1563/1563 [==============================] - 27s 17ms/step - loss: 0.1252 - sparse_categorical_accuracy: 0.9625 - val_loss: 1.1387 - val_sparse_categorical_accuracy: 0.7531
Epoch 56/100
1563/1563 [==============================] - 27s 17ms/step - loss: 0.1274 - sparse_categorical_accuracy: 0.9610 - val_loss: 1.2708 - val_sparse_categorical_accuracy: 0.7369
Epoch 57/100
1563/1563 [==============================] - 27s 17ms/step - loss: 0.1255 - sparse_categorical_accuracy: 0.9614 - val_loss: 1.1224 - val_sparse_categorical_accuracy: 0.7474
Epoch 58/100
1563/1563 [==============================] - 27s 17ms/step - loss: 0.1414 - sparse_categorical_accuracy: 0.9576 - val_loss: 1.1595 - val_sparse_categorical_accuracy: 0.7467
Epoch 59/100
1563/1563 [==============================] - 27s 17ms/step - loss: 0.1158 - sparse_categorical_accuracy: 0.9631 - val_loss: 1.3377 - val_sparse_categorical_accuracy: 0.7341
Epoch 60/100
1563/1563 [==============================] - 27s 17ms/step - loss: 0.1224 - sparse_categorical_accuracy: 0.9638 - val_loss: 1.2720 - val_sparse_categorical_accuracy: 0.7387
Epoch 61/100
1563/1563 [==============================] - 27s 17ms/step - loss: 0.1099 - sparse_categorical_accuracy: 0.9653 - val_loss: 1.2464 - val_sparse_categorical_accuracy: 0.7384
Epoch 62/100
1563/1563 [==============================] - 27s 17ms/step - loss: 0.1033 - sparse_categorical_accuracy: 0.9674 - val_loss: 1.1305 - val_sparse_categorical_accuracy: 0.7503
Epoch 63/100
1563/1563 [==============================] - 27s 17ms/step - loss: 0.1112 - sparse_categorical_accuracy: 0.9651 - val_loss: 1.2262 - val_sparse_categorical_accuracy: 0.7353
Epoch 64/100
1563/1563 [==============================] - 27s 17ms/step - loss: 0.1089 - sparse_categorical_accuracy: 0.9687 - val_loss: 1.1349 - val_sparse_categorical_accuracy: 0.7537
Epoch 65/100
1563/1563 [==============================] - 27s 17ms/step - loss: 0.1089 - sparse_categorical_accuracy: 0.9673 - val_loss: 1.3035 - val_sparse_categorical_accuracy: 0.7396
Epoch 66/100
1563/1563 [==============================] - 27s 17ms/step - loss: 0.1236 - sparse_categorical_accuracy: 0.9648 - val_loss: 1.1952 - val_sparse_categorical_accuracy: 0.7472
Epoch 67/100
1563/1563 [==============================] - 27s 17ms/step - loss: 0.1115 - sparse_categorical_accuracy: 0.9657 - val_loss: 1.2857 - val_sparse_categorical_accuracy: 0.7269
Epoch 68/100
1563/1563 [==============================] - 27s 17ms/step - loss: 0.4582 - sparse_categorical_accuracy: 0.8536 - val_loss: 1.1271 - val_sparse_categorical_accuracy: 0.7458
Epoch 69/100
1563/1563 [==============================] - 27s 17ms/step - loss: 0.1320 - sparse_categorical_accuracy: 0.9576 - val_loss: 1.2211 - val_sparse_categorical_accuracy: 0.7541
Epoch 70/100
1563/1563 [==============================] - 27s 17ms/step - loss: 0.0882 - sparse_categorical_accuracy: 0.9742 - val_loss: 1.2832 - val_sparse_categorical_accuracy: 0.7537
Epoch 71/100
1563/1563 [==============================] - 27s 17ms/step - loss: 0.0850 - sparse_categorical_accuracy: 0.9747 - val_loss: 1.1405 - val_sparse_categorical_accuracy: 0.7514
Epoch 72/100
1563/1563 [==============================] - 27s 17ms/step - loss: 0.0870 - sparse_categorical_accuracy: 0.9724 - val_loss: 1.2716 - val_sparse_categorical_accuracy: 0.7502
Epoch 73/100
1563/1563 [==============================] - 27s 17ms/step - loss: 0.1016 - sparse_categorical_accuracy: 0.9699 - val_loss: 1.1509 - val_sparse_categorical_accuracy: 0.7455
Epoch 74/100
1563/1563 [==============================] - 27s 17ms/step - loss: 0.1006 - sparse_categorical_accuracy: 0.9697 - val_loss: 1.2419 - val_sparse_categorical_accuracy: 0.7367
Epoch 75/100
1563/1563 [==============================] - 27s 17ms/step - loss: 0.1035 - sparse_categorical_accuracy: 0.9681 - val_loss: 1.2324 - val_sparse_categorical_accuracy: 0.7557
Epoch 76/100
1563/1563 [==============================] - 27s 17ms/step - loss: 0.0945 - sparse_categorical_accuracy: 0.9714 - val_loss: 1.2787 - val_sparse_categorical_accuracy: 0.7465
Epoch 77/100
1563/1563 [==============================] - 27s 17ms/step - loss: 0.1093 - sparse_categorical_accuracy: 0.9695 - val_loss: 1.2041 - val_sparse_categorical_accuracy: 0.7602
Epoch 78/100
1563/1563 [==============================] - 27s 17ms/step - loss: 0.1014 - sparse_categorical_accuracy: 0.9693 - val_loss: 1.1560 - val_sparse_categorical_accuracy: 0.7595
Epoch 79/100
1563/1563 [==============================] - 27s 17ms/step - loss: 0.0904 - sparse_categorical_accuracy: 0.9722 - val_loss: 1.2822 - val_sparse_categorical_accuracy: 0.7467
Epoch 80/100
1563/1563 [==============================] - 27s 17ms/step - loss: 0.0993 - sparse_categorical_accuracy: 0.9698 - val_loss: 1.1518 - val_sparse_categorical_accuracy: 0.7561
Epoch 81/100
1563/1563 [==============================] - 27s 17ms/step - loss: 0.0877 - sparse_categorical_accuracy: 0.9733 - val_loss: 1.2945 - val_sparse_categorical_accuracy: 0.7447
Epoch 82/100
1563/1563 [==============================] - 27s 17ms/step - loss: 0.1258 - sparse_categorical_accuracy: 0.9647 - val_loss: 1.3071 - val_sparse_categorical_accuracy: 0.7577
Epoch 83/100
1563/1563 [==============================] - 27s 17ms/step - loss: 0.0884 - sparse_categorical_accuracy: 0.9733 - val_loss: 1.2694 - val_sparse_categorical_accuracy: 0.7517
Epoch 84/100
1563/1563 [==============================] - 27s 17ms/step - loss: 0.1001 - sparse_categorical_accuracy: 0.9707 - val_loss: 1.2191 - val_sparse_categorical_accuracy: 0.7504
Epoch 85/100
1563/1563 [==============================] - 27s 17ms/step - loss: 0.0829 - sparse_categorical_accuracy: 0.9742 - val_loss: 1.3209 - val_sparse_categorical_accuracy: 0.7408
Epoch 86/100
1563/1563 [==============================] - 27s 17ms/step - loss: 0.0997 - sparse_categorical_accuracy: 0.9709 - val_loss: 1.3571 - val_sparse_categorical_accuracy: 0.7474
Epoch 87/100
1563/1563 [==============================] - 27s 17ms/step - loss: 0.1900 - sparse_categorical_accuracy: 0.9481 - val_loss: 1.1618 - val_sparse_categorical_accuracy: 0.7507
Epoch 88/100
1563/1563 [==============================] - 27s 17ms/step - loss: 0.1046 - sparse_categorical_accuracy: 0.9690 - val_loss: 1.3513 - val_sparse_categorical_accuracy: 0.7591
Epoch 89/100
1563/1563 [==============================] - 27s 17ms/step - loss: 0.0802 - sparse_categorical_accuracy: 0.9779 - val_loss: 1.3303 - val_sparse_categorical_accuracy: 0.7569
Epoch 90/100
1563/1563 [==============================] - 27s 17ms/step - loss: 0.0629 - sparse_categorical_accuracy: 0.9817 - val_loss: 1.3744 - val_sparse_categorical_accuracy: 0.7620
Epoch 91/100
1563/1563 [==============================] - 27s 17ms/step - loss: 0.0649 - sparse_categorical_accuracy: 0.9812 - val_loss: 1.2939 - val_sparse_categorical_accuracy: 0.7471
Epoch 92/100
1563/1563 [==============================] - 27s 17ms/step - loss: 0.0747 - sparse_categorical_accuracy: 0.9778 - val_loss: 1.2148 - val_sparse_categorical_accuracy: 0.7510
Epoch 93/100
1563/1563 [==============================] - 27s 17ms/step - loss: 0.0789 - sparse_categorical_accuracy: 0.9766 - val_loss: 1.3369 - val_sparse_categorical_accuracy: 0.7468
Epoch 94/100
1563/1563 [==============================] - 27s 17ms/step - loss: 0.0899 - sparse_categorical_accuracy: 0.9749 - val_loss: 1.2944 - val_sparse_categorical_accuracy: 0.7506
Epoch 95/100
1563/1563 [==============================] - 27s 17ms/step - loss: 0.0778 - sparse_categorical_accuracy: 0.9769 - val_loss: 1.6904 - val_sparse_categorical_accuracy: 0.6986
Epoch 96/100
1563/1563 [==============================] - 27s 17ms/step - loss: 0.1017 - sparse_categorical_accuracy: 0.9692 - val_loss: 1.3681 - val_sparse_categorical_accuracy: 0.7533
Epoch 97/100
1563/1563 [==============================] - 27s 17ms/step - loss: 0.0889 - sparse_categorical_accuracy: 0.9750 - val_loss: 1.3282 - val_sparse_categorical_accuracy: 0.7470
Epoch 98/100
1563/1563 [==============================] - 27s 17ms/step - loss: 0.1084 - sparse_categorical_accuracy: 0.9693 - val_loss: 1.2406 - val_sparse_categorical_accuracy: 0.7460
Epoch 99/100
1563/1563 [==============================] - 27s 17ms/step - loss: 0.0868 - sparse_categorical_accuracy: 0.9744 - val_loss: 1.5562 - val_sparse_categorical_accuracy: 0.7559
Epoch 100/100
1563/1563 [==============================] - 27s 17ms/step - loss: 0.0769 - sparse_categorical_accuracy: 0.9777 - val_loss: 1.3857 - val_sparse_categorical_accuracy: 0.7503
Model: "vg_g16"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d (Conv2D)              multiple                  1792      
_________________________________________________________________
batch_normalization (BatchNo multiple                  256       
_________________________________________________________________
activation (Activation)      multiple                  0         
_________________________________________________________________
conv2d_1 (Conv2D)            multiple                  36928     
_________________________________________________________________
batch_normalization_1 (Batch multiple                  256       
_________________________________________________________________
activation_1 (Activation)    multiple                  0         
_________________________________________________________________
max_pooling2d (MaxPooling2D) multiple                  0         
_________________________________________________________________
dropout (Dropout)            multiple                  0         
_________________________________________________________________
conv2d_2 (Conv2D)            multiple                  73856     
_________________________________________________________________
batch_normalization_2 (Batch multiple                  512       
_________________________________________________________________
activation_2 (Activation)    multiple                  0         
_________________________________________________________________
conv2d_3 (Conv2D)            multiple                  147584    
_________________________________________________________________
batch_normalization_3 (Batch multiple                  512       
_________________________________________________________________
activation_3 (Activation)    multiple                  0         
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 multiple                  0         
_________________________________________________________________
dropout_1 (Dropout)          multiple                  0         
_________________________________________________________________
conv2d_4 (Conv2D)            multiple                  295168    
_________________________________________________________________
batch_normalization_4 (Batch multiple                  1024      
_________________________________________________________________
activation_4 (Activation)    multiple                  0         
_________________________________________________________________
conv2d_5 (Conv2D)            multiple                  590080    
_________________________________________________________________
batch_normalization_5 (Batch multiple                  1024      
_________________________________________________________________
activation_5 (Activation)    multiple                  0         
_________________________________________________________________
conv2d_6 (Conv2D)            multiple                  590080    
_________________________________________________________________
batch_normalization_6 (Batch multiple                  1024      
_________________________________________________________________
activation_6 (Activation)    multiple                  0         
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 multiple                  0         
_________________________________________________________________
dropout_2 (Dropout)          multiple                  0         
_________________________________________________________________
conv2d_7 (Conv2D)            multiple                  1180160   
_________________________________________________________________
batch_normalization_7 (Batch multiple                  2048      
_________________________________________________________________
activation_7 (Activation)    multiple                  0         
_________________________________________________________________
conv2d_8 (Conv2D)            multiple                  2359808   
_________________________________________________________________
batch_normalization_8 (Batch multiple                  2048      
_________________________________________________________________
activation_8 (Activation)    multiple                  0         
_________________________________________________________________
conv2d_9 (Conv2D)            multiple                  2359808   
_________________________________________________________________
batch_normalization_9 (Batch multiple                  2048      
_________________________________________________________________
activation_9 (Activation)    multiple                  0         
_________________________________________________________________
max_pooling2d_3 (MaxPooling2 multiple                  0         
_________________________________________________________________
dropout_3 (Dropout)          multiple                  0         
_________________________________________________________________
conv2d_10 (Conv2D)           multiple                  2359808   
_________________________________________________________________
batch_normalization_10 (Batc multiple                  2048      
_________________________________________________________________
activation_10 (Activation)   multiple                  0         
_________________________________________________________________
conv2d_11 (Conv2D)           multiple                  2359808   
_________________________________________________________________
batch_normalization_11 (Batc multiple                  2048      
_________________________________________________________________
activation_11 (Activation)   multiple                  0         
_________________________________________________________________
conv2d_12 (Conv2D)           multiple                  2359808   
_________________________________________________________________
batch_normalization_12 (Batc multiple                  2048      
_________________________________________________________________
activation_12 (Activation)   multiple                  0         
_________________________________________________________________
max_pooling2d_4 (MaxPooling2 multiple                  0         
_________________________________________________________________
dropout_4 (Dropout)          multiple                  0         
_________________________________________________________________
flatten (Flatten)            multiple                  0         
_________________________________________________________________
dense (Dense)                multiple                  262656    
_________________________________________________________________
dropout_5 (Dropout)          multiple                  0         
_________________________________________________________________
dense_1 (Dense)              multiple                  262656    
_________________________________________________________________
dropout_6 (Dropout)          multiple                  0         
_________________________________________________________________
dense_2 (Dense)              multiple                  5130      
=================================================================
Total params: 15,262,026
Trainable params: 15,253,578
Non-trainable params: 8,448
_________________________________________________________________

Process finished with exit code 0
2080 Ti 60min